# Transformers.js + Next.js (Client-Side LLM Playground)

**Next.js â€¢ Hugging Face Transformers.js â€¢ Web Workers**

This project is a fully client-side Next.js playground for running lightweight LLMs directly in the browser using [Hugging Face's Transformers.js](https://huggingface.co/docs/transformers.js/). It demonstrates how to integrate LLM inference and embeddings without server dependencies, making it ideal for privacy-focused or offline-compatible AI applications.

---

## ðŸ”‘ Key Features

- âœ… Runs entirely in the browser â€” no backend or API keys required  
- âœ… Supports text generation and embedding pipelines with Transformers.js  
- âœ… Uses a Web Worker to offload model computation, keeping the UI responsive  
- âœ… Example setup for deploying small ONNX LLM models like Phi-4 Mini or DistilGPT2  
- âœ… Clean, minimal Next.js architecture for easy extension or experimentation  

---

## âš¡ Use Cases

- Private, browser-based chatbots  
- AI-powered tools that work offline  
- Educational demos for LLMs in the browser  
- Rapid prototyping for client-side AI applications  

---

## ðŸ“¦ Tech Stack

- [Next.js](https://nextjs.org/)  
- [Transformers.js](https://huggingface.co/docs/transformers.js/)  
- [ONNX Runtime Web](https://www.npmjs.com/package/onnxruntime-web)  
- Web Workers  

---

This project serves as a foundation for building private, client-side AI tools with modern web technology.

