Transformers.js + Next.js (Client-Side LLM Playground)
Next.js • Hugging Face Transformers.js • Web Workers

This project is a fully client-side Next.js playground for running lightweight LLMs directly in the browser using Hugging Face's Transformers.js. It demonstrates how to integrate LLM inference and embeddings without server dependencies, ideal for privacy-focused or offline-compatible AI applications.

Key features:
✅ Runs entirely in the browser — no backend or API keys required
✅ Supports text generation and embedding pipelines with Transformers.js
✅ Uses a Web Worker to offload model computation, keeping the UI responsive
✅ Example setup for deploying small ONNX LLM models like Phi-4 Mini or DistilGPT2
✅ Clean, minimal Next.js architecture for easy extension or experimentation
This project serves as a foundation for building private, client-side AI tools, chatbots, or educational demos leveraging modern browser capabilities.
